{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Chemical Reaction Networks with ppsim\n",
    "\n",
    "``ppsim`` is able to simulate any Chemical Reaction Network (CRN) whose reactions are all bimolecular (two reactant, two product) or unimolecular (one reactant, one product). This notebook shows some examples of that feature, and how it compares to the standard Gillespie stochastic simulation algorithm.\n",
    "\n",
    "This notebook is intended to be statically readable on GitHub, without needing to run it locally. However, after installing ppsim, you can download the notebook and run its cells to re-generate the data yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import ppsim as pp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "# Uncomment this line to make all plots interactive\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate majority CRN\n",
    "\n",
    "This 3-state CRN reaches a consensus between the two initial states ``A`` and ``B``. Opposite opinions become undecided ``U`` states, which are then converted by the ``A`` and ``B`` states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a,b,u = pp.species('A B U')\n",
    "approx_majority = [\n",
    "    a+b >> 2*u,\n",
    "    a+u >> 2*a,\n",
    "    b+u >> 2*b,\n",
    "]\n",
    "n = 10 ** 2\n",
    "p = 0.51\n",
    "a_init = int(n * p)\n",
    "b_init = n - a_init\n",
    "inits = {a: a_init, b: b_init}\n",
    "# for seed in range(100):\n",
    "#     print(f'{seed=}')\n",
    "seed = 10\n",
    "sim = pp.Simulation(inits, approx_majority, seed=seed)\n",
    "sim.run(20, 0.1)\n",
    "# sim.run(20, history_interval=0.1)\n",
    "sim.history.plot(figsize=(10,5)) # .plot(figsize = (6, 4))\n",
    "plt.title('approximate majority (ppsim)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the input was in the form of a CRN, `ppsim` by default is using the same continuous time model as the Gillespie algorithm. We can check that it is the same by implementing the same protocol using Gillespie simulation with the package [GillesPy2](https://github.com/StochSS/GillesPy2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gillespy2\n",
    "# model = pp.gillespy2_format(inits, approx_majority, n)\n",
    "# model.timespan(np.linspace(0,16,200))\n",
    "# results = model.run()\n",
    "# results.plot(figsize=(8,4), title='approximate majority (GillesPy2)')\n",
    "# plt.ylabel('count')\n",
    "# end_time = 5\n",
    "# line = plt.vlines(end_time, 0, n, color='r',linestyles = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpac as gp\n",
    "tmax = 10\n",
    "nb_steps = 200\n",
    "gp_inits, gp_rxns = pp.gpac_format(inits, approx_majority)\n",
    "tmax = 16\n",
    "seed=0\n",
    "_=gp.plot_gillespie(gp_rxns, gp_inits, tmax, nb_steps=nb_steps, seed=seed)\n",
    "# results = model.run()\n",
    "# results.plot(figsize=(8,4), title='approximate majority (GillesPy2)')\n",
    "# plt.ylabel('count')\n",
    "# end_time = 5\n",
    "# line = plt.vlines(end_time, 0, n, color='r',linestyles = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that was used to generate the data, which was saved with pickle\n",
    "# This is commented out since it is time-consuming to run. \n",
    "# Uncomment the code below to re-run and generate new data for the next figure.\n",
    "exponent = 4\n",
    "trials = 10 ** exponent\n",
    "end_time = 5\n",
    "sim = pp.Simulation(inits, approx_majority)\n",
    "results_ppsim = sim.sample_future_configuration(end_time, num_samples = trials)\n",
    "results_rebop = gp.rebop_sample_future_configurations(approx_majority, inits, end_time, trials=trials)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "ax.hist([results_ppsim['A'], results_rebop[a]], bins = np.linspace(0, n, 20), \n",
    "        alpha = 1, label=['ppsim', 'rebop']) #, density=True, edgecolor = 'k', linewidth = 0.5)\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel(f'count of state A')\n",
    "ax.set_ylabel(f'empirical probability (10^{exponent} total samples)')\n",
    "ax.set_title('state distribution sampled at simulated time 5')\n",
    "\n",
    "pickle.dump((fig, ax), open( \"crn_data/am_distributions.p\", \"wb\" ) )\n",
    "plt.savefig('crn_data/am2.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test more thoroughly that these two simulations have the exact same distribution, we will sample the probability distribution of a state at time 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Code that was used to generate the data, which was saved with pickle\n",
    "# # This is commented out since it is time-consuming to run. \n",
    "# # Uncomment the code below to re-run and generate new data for the next figure.\n",
    "# trials = 10 ** 6\n",
    "# sim = pp.Simulation(init_config, approx_majority)\n",
    "# results_ppsim = sim.sample_future_configuration(end_time, num_samples = trials)\n",
    "\n",
    "# model.timespan(np.linspace(0,end_time,2))\n",
    "# results_gillespy2 = model.run(number_of_trajectories = trials)\n",
    "# fig, ax = plt.subplots(figsize = (4,4))\n",
    "# ax.hist([results_ppsim['A'], [result['A'][1] for result in results_gillespy2]], bins = np.linspace(0, n, 20), \n",
    "#                           alpha = 1, label=['ppsim', 'GillesPy2'], density=True, edgecolor = 'k', linewidth = 0.0)\n",
    "# ax.legend()\n",
    "# ax.set_xlabel(f'count of state A')\n",
    "# ax.set_ylabel('empirical probability (10^6 total samples)')\n",
    "# ax.set_title('state distribution sampled at simulated time 5')\n",
    "\n",
    "# pickle.dump((fig, ax), open( \"crn_data/am_distributions.p\", \"wb\" ) )\n",
    "# plt.savefig('crn_data/am2.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we gave a CRN as input, `ppsim` ran with continuous time, and both it and GillesPy2 should be exactly sampling from the same chemical master equation. We will plot both distributions on a histogram to show how well they match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pd.read_pickle( open( \"crn_data/am_distributions.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are sampling from the same distribution, but we will see that `ppsim` can do it much faster for larger population sizes. We will repeatedly sample this approximate majority at time step 10, for varying population sizes, and compute the average running time used per sample generated. We calculate this average time per sample to try to amortize the time spent initializing the simulation and saving data, trying to focus on the runtime of the simulation algorithm itself.\n",
    "\n",
    "We will compare `ppsim` to GillesPy2, as well as the package [StochKit2](https://academic.oup.com/bioinformatics/article/27/17/2457/224105), which can run multiple variants of Gillespie's algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import os\n",
    "\n",
    "def time_trials(simulator, ns, num_trials = 10000, adaptive=True):\n",
    "    # get data on time it takes ppsim to run rule from init_config until end_time\n",
    "    times = []\n",
    "    for n in ns:\n",
    "        print(f'n = {n:.2E}')\n",
    "        sim = simulator(n)\n",
    "        start_time = perf_counter()\n",
    "        sim.run(num_trials)\n",
    "        trial_time = (perf_counter() - start_time) / num_trials\n",
    "        times.append(trial_time)\n",
    "        # set num_trials to be at most the number that this one could have finished in 10 seconds\n",
    "        if trial_time > 400:\n",
    "            break\n",
    "        if adaptive:\n",
    "            num_trials = min(num_trials, math.ceil(10 / trial_time))\n",
    "        clear_output(wait=True)\n",
    "    return times\n",
    "\n",
    "# redefining this function will change the rule that the trials use\n",
    "def sim_params(n):\n",
    "    # returns init_config, rxns, vol\n",
    "    return {a: n // 2, b: n // 2}, approx_majority, n\n",
    "\n",
    "class gillespy2_trials:\n",
    "    def __init__(self, n):\n",
    "        self.model = pp.gillespy2_format(*sim_params(n))\n",
    "        self.model.timespan([0,end_time])\n",
    "    def run(self, num_trials):\n",
    "        self.model.run(number_of_trajectories=num_trials)\n",
    "\n",
    "class ppsim_trials:\n",
    "    def __init__(self, n):\n",
    "        self.sim = pp.Simulation(*sim_params(n)[0:2])\n",
    "    def run(self, num_trials):\n",
    "        self.sim.sample_future_configuration(end_time, num_trials)\n",
    "        \n",
    "# In order to run stochkit_trials, need a stochkit package in the environment variable STOCHKIT_HOME\n",
    "class stochkit_trials:\n",
    "    def __init__(self, n):\n",
    "        # save to build folder, which is in .gitignore\n",
    "        self.filename = 'build/stochkit_trial.xml'\n",
    "        init_config, rxns, vol = sim_params(n)\n",
    "        pp.write_stochkit_file(self.filename, *sim_params(n))\n",
    "        self.cmd = os.path.join(os.environ['STOCHKIT_HOME'], 'ssa')\n",
    "    def run(self, num_trials):\n",
    "        self.cmd += ' -m ' + self.filename + ' -r ' + str(num_trials) + ' -t ' + str(end_time) + ' -f'\n",
    "        os.system(self.cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Code that was used to generate the data, which was saved with pickle\n",
    "# ns = [int(n) for n in np.geomspace(10 ** 1, 10 ** 12, 23)]\n",
    "# end_time = 10\n",
    "# num_trials = 1000\n",
    "# methods = [ppsim_trials, gillespy2_trials, stochkit_trials]\n",
    "# method_times2 = [time_trials(method, ns) for method in methods]\n",
    "# pickle.dump(method_times, open( \"crn_data/am_runtimes.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickled data to plot\n",
    "method_times = pd.read_pickle( open( \"crn_data/am_runtimes.p\", \"rb\" ))\n",
    "ns = [int(n) for n in np.geomspace(10 ** 1, 10 ** 12, 23)]\n",
    "fig = plt.figure()\n",
    "for times in method_times:\n",
    "    plt.plot(ns[2:len(times)], times[2:], 'o-')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('population size')\n",
    "plt.ylabel('running time (s) / sample generated')\n",
    "plt.xticks(ns[2::2])\n",
    "plt.title('Running time to sample approximate majority at simulated time 10')\n",
    "plt.legend(['ppsim', 'GillesPy2', 'StochKit2'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runtime plots are reflecting that the Gillespie algorithm implemented by GillesPy2 and StochKit has $O(n)$ runtime (roughly slope 1 on log-log plot), wheras ``ppsim`` has $O(\\sqrt{n})$ runtime (roughly slope 1/2 on log-log plot).\n",
    "\n",
    "Using ``ppsim``, we are able to simulate populations into the trillions. This lets us exactly simulate counts of molecules approaching those used in real experiments. This approximate majority protocol has been implemented experimentally by DNA strand displacement in [this paper](https://pubmed.ncbi.nlm.nih.gov/24077029/). We can set the approximate majority rate constants to be effective rate constants from the paper, and using the concentration 80 nM from the paper in a volume of 1 microliter, we have a system of nearly $10^{11}$ molecules, which can be ``ppsim`` can handle. We note that the actual reactions implemented experimentally in the paper are dozens of DNA strand displacement reactions that implement the 3-reaction protocol. What is shown below is not this; it is just the three \"abstract\" reactions doing approximate majority directly. (But with simulated experimental conditions set to be realistic, assuming one could find chemicals implementing the approximate majority reactions more directly than DNA strand displacement.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# derived rate constants of the formal reaction simulated by DNA strand displacement (units of /M/s)\n",
    "k1,k2,k3 = 9028, 2945, 1815\n",
    "total_concentration = 80 * 1e-9 # 1x volume was 80 nM\n",
    "vol = 1e-6 # 1 uL\n",
    "n = pp.concentration_to_count(total_concentration, vol)\n",
    "approx_majority_rates = [\n",
    "    (a+b >> 2*u).k(k1, units=pp.RateConstantUnits.mass_action),\n",
    "    (a+u >> 2*a).k(k2, units=pp.RateConstantUnits.mass_action),\n",
    "    (b+u >> 2*b).k(k3, units=pp.RateConstantUnits.mass_action),\n",
    "]\n",
    "# set the initial concentrations near where the the mass-action CRN would reach an unstable equilibrium\n",
    "p = 0.45\n",
    "inits = {a: int(p*n), b: int((1-p)*n)}\n",
    "sim = pp.Simulation(inits, approx_majority_rates, volume=vol, time_units='seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In non-interactive mode, we wait to run the simulation before plotting\n",
    "# %time sim.run()\n",
    "sim.run()\n",
    "sim.history.plot()\n",
    "plt.title('approximate majority, experimental conditions')\n",
    "plt.ylabel('count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If we are in interactive matplotlib mode (%matplotlib widget), then we can view the plot in real time while the simulation is running\n",
    "# sim.reset()\n",
    "# hp = pp.HistoryPlotter()\n",
    "# sim.add_snapshot(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First the HistoryPlotter must be added in one cell, then run has to be called in the next cell to see live updates\n",
    "# sim.run()\n",
    "# hp.ax.set_title('approximate majority, experimental conditions')\n",
    "# hp.ax.set_ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large State Speed Tests\n",
    "\n",
    "The core of `ppsim` uses batching algorithms from [this paper](https://arxiv.org/abs/2005.03584). Theoretically, the time for the basic batching algorithm to simulate $\\Theta(\\sqrt{n})$ scales in the worst case as $O(q^2)$, where $q$ is the total number of states. The MultiBatch variant improves this worse case scaling to $O(q\\sqrt{\\log(n)})$ to simulate $\\Theta(\\sqrt{n})$ interactions, so the asymptotic gains in runtime only apply to state sets $q = o(\\sqrt{n})$.\n",
    "\n",
    "We will now test how this running time scales with number of states. The 3-state approximate majority CRN was one of the best possible cases, so we will now run some speed tests with parameterized CRNs that have a variable number of states.\n",
    "\n",
    "We found StochKit2 to be much more competitive in these trials, so we will only show comparisons between in and `ppsim`. We will fix the population size $n = 10^4$, which was the spot where both algorithms had the same runtime for approximate majority. By only varying the number of states in the protocol, we will then isolate the effect of increased state set.\n",
    "\n",
    "These effects crucially depend on the number of types of reactions, so we will try a few different CRNs. The first example will be a chain of unimolecular decay reactions, where each of `m` states decays into the next. The reactions are\n",
    "$$s_0 \\rightarrow s_1 \\rightarrow s_2 \\rightarrow \\ldots \\rightarrow s_{m-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unimolecular_chain(m):\n",
    "    # create reactions with m species s0, ..., s(m-1)\n",
    "    states = pp.species(' '.join(['s' + str(i) for i in range(m)]))\n",
    "    rxns = [states[i] >> states[i+1] for i in range(m-1)]\n",
    "    return states, rxns\n",
    "states, rxns = get_unimolecular_chain(10)\n",
    "n = 10000\n",
    "sim = pp.Simulation({states[0]: n}, rxns)\n",
    "sim.run(history_interval=0.1)\n",
    "sim.history.plot()\n",
    "plt.ylabel('count')\n",
    "plt.yscale('symlog')\n",
    "plt.ylim(0, 2*n)\n",
    "plt.title('unimolecular decay chain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot with time on a linear scale and counts on a log scale shows that each state is successively decaying exponentially to 0.\n",
    "\n",
    "Unlike in the above plot, our comparisons will use an initial configuration which is a uniform mix of all `m` states, and run to simulated time 10. This is to ensure that we can test for a fixed amount of time and have all reactions be active simulatenously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 ** 4\n",
    "end_time = 10\n",
    "\n",
    "# Redefine the sim_params function\n",
    "def sim_params(m):\n",
    "    # returns init_config, rxns, vol\n",
    "    states, rxns = get_unimolecular_chain(m)\n",
    "    return {state:n // m for state in states}, rxns, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code that was used to generate the data, which was saved with pickle\n",
    "# ms = [int(m) for m in np.linspace(2, 200, 20)]\n",
    "# methods = [ppsim_trials, stochkit_trials]\n",
    "# method_times = [time_trials(method, ms, num_trials=1000, adaptive=False) for method in methods]\n",
    "# pickle.dump(method_times, open( \"crn_data/unimolecular_runtimes.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickled data to plot\n",
    "method_times = pd.read_pickle( open( \"crn_data/unimolecular_runtimes.p\", \"rb\" ))\n",
    "ms = [int(m) for m in np.linspace(2, 200, 20)]\n",
    "fig = plt.figure()\n",
    "for times in method_times:\n",
    "    plt.plot(ms[:len(times)], times, 'o-')\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.xlabel('number of states (fixed population size n = 10000)')\n",
    "plt.ylabel('running time (s) / sample generated')\n",
    "plt.title('Running time to sample unimolecular decay chain at simulated time 10')\n",
    "plt.legend(['ppsim', 'StochKit2'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see for this example that holding the number of states fixed, `ppsim` scales worse in terms of number of states than StochKit2. As expected, the time is scaling linearly with `ppsim`, whereas the change in StochKit's running time is very marginal.\n",
    "Note that the largest state set $q = 200 > \\sqrt{n}$ for this fixed value $n = 10^4$, so it was not expected for MultiBatch to outperform a more direct sequential population protocol simulation in this case.\n",
    "\n",
    "But we will now check that even for large state sets, the gains from MultiBatch are still large as we look at larger population sizes. We will fix the state set $m=200$ to be constant, as $n$ increases starting from $n = 10^4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = 10\n",
    "m = 200\n",
    "def sim_params(n):\n",
    "    # returns init_config, rxns, vol\n",
    "    states, rxns = get_unimolecular_chain(m)\n",
    "    return {state:n // m for state in states}, rxns, n\n",
    "\n",
    "# # Code that was used to generate the data, which was saved with pickle\n",
    "# ns = [int(n) for n in np.geomspace(10 ** 4, 10 ** 10, 13)]\n",
    "# methods = [ppsim_trials, stochkit_trials]\n",
    "# method_times2 = [time_trials(method, ns, num_trials=100) for method in methods]\n",
    "# pickle.dump(method_times, open( \"crn_data/unimolecular_runtimes2.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickled data to plot\n",
    "method_times = pd.read_pickle( open( \"crn_data/unimolecular_runtimes2.p\", \"rb\" ))\n",
    "ns = [int(n) for n in np.geomspace(10 ** 4, 10 ** 10, 13)]\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "for times in method_times:\n",
    "    plt.plot(ns[:len(times)], times, 'o-')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('population size n (fixed number of states m=200)')\n",
    "plt.ylabel('running time (s) / sample generated')\n",
    "plt.title('Running time to sample unimolecular decay chain at simulated time 10')\n",
    "plt.legend(['ppsim', 'StochKit2'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will look at a chain where each reaction is bimolecular:\n",
    "$$2s_0 \\rightarrow 2s_1 \\rightarrow 2s_2 \\rightarrow \\ldots \\rightarrow 2s_{m-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bimolecular_chain(m):\n",
    "    # create reactions with m species s0, ..., s(m-1)\n",
    "    states = pp.species(' '.join(['s' + str(i) for i in range(m)]))\n",
    "    rxns = [2*states[i] >> 2 * states[i+1] for i in range(m-1)]\n",
    "    return states, rxns\n",
    "states, rxns = get_bimolecular_chain(10)\n",
    "n = 10 ** 4\n",
    "sim = pp.Simulation({states[0]: n}, rxns)\n",
    "# Setting history_interval to be a function lets the recorded timesteps be evenly spaced on a log plot\n",
    "sim.run(history_interval=lambda t: 10 ** len(str(int(t))) / 100)\n",
    "sim.history.plot()\n",
    "plt.xscale('symlog')\n",
    "plt.xlim(0, sim.times[-1])\n",
    "plt.yscale('symlog')\n",
    "plt.ylabel('count')\n",
    "plt.ylim(0, 2*n)\n",
    "plt.title('bimolecular decay')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a plot with time and counts on a log scale shows that each state successive decays polynomially to 0. Because `ppsim` dynamically switches to Gillespie's algorithm when the number of null interactions gets very high, it can quickly go out to large times if the system is waiting on a small number of reactions to complete.\n",
    "\n",
    "Again, unlike in the above plot, our comparisons will use an initial configuration which is a uniform mix of all `m` states, and run to simulated time 10. This is to ensure that we can test for a fixed amount of time and have all reactions be active simulatenously. Note that the probability of an active reaction decreases as we increase the state set `m`. This means the number of non-null interactions that happen in 10 units of time will decrease. The optimized Gillespie algorithm of StockKit2 will thus need to simulate fewer reactions, whereas the MultiBatch algorithm for `ppsim` needs to simulate these null interactions as well. As the probability of a null interaction grows, the relative advantage of MultiBatch drops, until eventually when this probability of a null interaction gets sufficiently high, `ppsim` will switch to a direct Gillespie algorithm. This bimolecular chain is thus representing the worst case for `ppsim`, because increasing the parameter `m` directly increases the probability of a null interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 ** 4\n",
    "end_time = 10\n",
    "\n",
    "def sim_params(m):\n",
    "    # returns init_config, rxns, vol\n",
    "    states, rxns = get_bimolecular_chain(m)\n",
    "    return {state:n // m for state in states}, rxns, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code that was used to generate the data, which was saved with pickle\n",
    "# ms = [int(m) for m in np.linspace(2, 200, 20)]\n",
    "# methods = [ppsim_trials, stochkit_trials]\n",
    "# method_times = [time_trials(method, ms, num_trials=100, adaptive=False) for method in methods]\n",
    "# pickle.dump(method_times, open( \"crn_data/bimolecular_runtimes.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickled data to plot\n",
    "method_times = pd.read_pickle( open( \"crn_data/bimolecular_runtimes.p\", \"rb\" ))\n",
    "ms = [int(m) for m in np.linspace(2, 200, 20)]\n",
    "fig = plt.figure()\n",
    "for times in method_times:\n",
    "    plt.plot(ms[:len(times)], times, 'o-')\n",
    "plt.xlabel('number of states (fixed population size n = 10000)')\n",
    "plt.ylabel('running time (s) / sample generated')\n",
    "plt.title('Running time to sample bimolecular decay chain at simulated time 10')\n",
    "plt.legend(['ppsim', 'StochKit2'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the a similar linear increase in running time with respect to number of states from `ppsim`. The running time for StockKit2 doesn't change at all, as the cost to handle a larger number of states is being offset by the fact that fewer reactions happen by simulated time 10.\n",
    "\n",
    "Again, we will take the largest number 200 of states and now increase the population size, to see when `ppsim` becomes more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = 10\n",
    "m = 200\n",
    "n = 10 ** 4\n",
    "def sim_params(n):\n",
    "    # returns init_config, rxns, vol\n",
    "    states, rxns = get_bimolecular_chain(m)\n",
    "    return {state:n // m for state in states}, rxns, n\n",
    "\n",
    "# # Code that was used to generate the data, which was saved with pickle\n",
    "# ns = [int(n) for n in np.geomspace(10 ** 3, 10 ** 12, 19)]\n",
    "# methods = [ppsim_trials, stochkit_trials]\n",
    "# method_times = [time_trials(method, ns, num_trials=1000) for method in methods]\n",
    "# pickle.dump(method_times, open( \"crn_data/bimolecular_runtimes2.p\", \"wb\" ) )\n",
    "\n",
    "# load the pickled data to plot\n",
    "method_times = pd.read_pickle( open( \"crn_data/bimolecular_runtimes2.p\", \"rb\" ))\n",
    "ns = [int(n) for n in np.geomspace(10 ** 3, 10 ** 12, 19)]\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "for times in method_times:\n",
    "    plt.plot(ns[2:len(times)], times[2:], 'o-')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('population size n (fixed number of states m=200)')\n",
    "plt.ylabel('running time (s) / sample generated')\n",
    "plt.title('Running time to sample bimolecular decay chain at simulated time 10')\n",
    "plt.legend(['ppsim', 'StochKit2'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very high probability of null reactions imposes a significant constant-factor penalty to `ppsim`, but still its quadratic speedup eventually overcomes this disadvantage for sizes $n \\geq 10^{10}$.\n",
    "\n",
    "We will next check at a more reasonable state space of $m=50$ for a further comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = 10\n",
    "m = 20\n",
    "n = 10 ** 4\n",
    "def sim_params(n):\n",
    "    # returns init_config, rxns, vol\n",
    "    states, rxns = get_bimolecular_chain(m)\n",
    "    return {state:n // m for state in states}, rxns, n\n",
    "\n",
    "# # Code that was used to generate the data, which was saved with pickle\n",
    "# ns = [int(n) for n in np.geomspace(10 ** 3, 10 ** 10, 15)]\n",
    "# methods = [ppsim_trials, stochkit_trials]\n",
    "# method_times = [time_trials(method, ns, num_trials=1000) for method in methods]\n",
    "# pickle.dump(method_times, open( \"crn_data/bimolecular_runtimes3.p\", \"wb\" ) )\n",
    "\n",
    "# load the pickled data to plot\n",
    "method_times = pd.read_pickle( open( \"crn_data/bimolecular_runtimes3.p\", \"rb\" ))\n",
    "ns = [int(n) for n in np.geomspace(10 ** 3, 10 ** 10, 15)]\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "for times in method_times:\n",
    "    plt.plot(ns[2:len(times)], times[2:], 'o-')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('population size n (fixed number of states m=20)')\n",
    "plt.ylabel('running time (s) / sample generated')\n",
    "plt.title('Running time to sample bimolecular decay chain at simulated time 10')\n",
    "plt.legend(['ppsim', 'StochKit2'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will consider a parameterized discrete averaging rule, with reactions\n",
    "$$s_i + s_j \\rightarrow s_{\\lfloor{\\frac{i+j}{2}}\\rfloor} + s_{\\lceil{\\frac{i+j}{2}}\\rceil}$$\n",
    "Starting from states $s_0$ and $s_{m-1}$, all $m$ states will soon become present via these averaging rules. Unlike our first two examples, now the total number of reactions is $O(m^2)$, as almost all pairs have a non-null interaction (as long as $|i-j|>1$ then $s_i$ and $s_j$ have an active reaction). This change makes no difference for `ppsim`, but will make the simulation much more expensive for GillesPy2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discrete_averaging(m):\n",
    "    # create reactions with m species s0, ..., s(m-1)\n",
    "    states = pp.species(' '.join(['s'+str(i) for i in range(m)]))\n",
    "    rxns = []\n",
    "    for i in range(m):\n",
    "        for j in range(i):\n",
    "            avg = (i + j) / 2\n",
    "            rxns.append(states[i] + states[j] >> states[math.floor(avg)] + states[math.ceil(avg)])\n",
    "    return states, rxns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 ** 4\n",
    "end_time = 10\n",
    "\n",
    "def sim_params(m):\n",
    "    # returns init_config, rxns, vol\n",
    "    states, rxns = get_discrete_averaging(m)\n",
    "    return {states[0]: n // 2, states[m-1]: n // 2}, rxns, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code that was used to generate the data, which was saved with pickle\n",
    "# ms = [int(m) for m in np.linspace(3, 200, 20)]\n",
    "\n",
    "# methods = [ppsim_trials, stochkit_trials]\n",
    "# method_times = [time_trials(method, ms, num_trials=100) for method in methods]\n",
    "# pickle.dump(method_times, open( \"crn_data/discrete_averaging_runtimes.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickled data to plot\n",
    "method_times = pd.read_pickle( open( \"crn_data/discrete_averaging_runtimes.p\", \"rb\" ))\n",
    "fig, ax = plt.subplots()\n",
    "for times in method_times:\n",
    "    plt.plot(ms[:len(times)], times, 'o-')\n",
    "# plt.yscale('log')\n",
    "# plt.ylim(0, 2)\n",
    "plt.xlabel('number of states (fixed population size n = 10000)')\n",
    "plt.ylabel('running time (s)')\n",
    "plt.title('Running time to sample discrete averaging at simulated time 10')\n",
    "plt.legend(['ppsim', 'StochKit2'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of states grows, the quadratic growth in the number of reactions to be processed by StochKit2 becomes very expensive. For `ppsim`, on the other hand, there is little difference between this CRN and the previous rules, since its scaling is only on the number of states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_ylim(0,0.02)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RPS Oscillator\n",
    "\n",
    "We will now look at a simple 3-state CRN with oscillatory dynamics, given by the reactions\n",
    "$$B+A \\rightarrow B + B$$\n",
    "$$C + B \\rightarrow C + C$$\n",
    "$$A + C \\rightarrow A + A$$\n",
    "\n",
    "The behavior of this CRN under the exact stochastic dyanamics which are sampled by Gillespie's algorithm turns out to be very delicate. This example will show that common approximations to quickly simulate this CRN for large state sizes, both $\\tau$-leaping and ODE simulation, each have qualitatively different behavior from the true stochastic simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRN for rps oscillator\n",
    "a,b,c = pp.species('A B C')\n",
    "rps = [\n",
    "    b+a >> 2*b,\n",
    "    c+b >> 2*c,\n",
    "    a+c >> 2*a,\n",
    "]\n",
    "n = 10 ** 4\n",
    "dist = [0.2, 0.3, 0.5]\n",
    "init_config = {a: n * dist[0], b: n * dist[1], c: n * dist[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pp.gillespy2_format(init_config, rps, n)\n",
    "model.timespan(np.linspace(0,200,3000))\n",
    "results = model.run()\n",
    "results.plot(figsize = (18, 4), title='rps oscillator')\n",
    "plt.ylim(0, n)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amplitude of the oscillations randomly drifts up and down during the simulation. For another way to visualize these dynamics, we can take a look at the curves traced out in phase space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import warnings\n",
    "# Need the scipy package to plot ODE solutions\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "def odes(t, y):\n",
    "    a, b, c = y[0], y[1], y[2]\n",
    "    return a*(c-b), b*(a-c), c*(b-a)\n",
    "\n",
    "def phase_plot(results):\n",
    "     # Some warnings appear only when in %matplotlib inline mode\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    verts = [[n,0,0],[0,n,0],[0,0,n]]\n",
    "\n",
    "    simplex = Poly3DCollection([verts], edgecolors='k', facecolors='w', alpha=0.1)\n",
    "    ax.scatter(*np.array(verts), color='k')\n",
    "    ax.add_collection3d(simplex)\n",
    "    e = 0.05\n",
    "    ax.text((1-2*e)*n, e*n, e*n, 'A')\n",
    "    ax.text(e*n, (1-2*e)*n, e*n, 'B')\n",
    "    ax.text(e*n, e*n, (1-2*e)*n, 'C')\n",
    "\n",
    "    ax.plot(results['A'], results['B'], results['C'], lw=0.5, label='stochastic trajectory')\n",
    "    ax.set_xlabel('A')\n",
    "    ax.set_ylabel('B')\n",
    "    ax.set_zlabel('C')\n",
    "    ax.set_xlim(0, n)\n",
    "    ax.set_ylim(0, n)\n",
    "    ax.set_zlim(0, n)\n",
    "    ax.set_title(\"rps oscillator\")\n",
    "    ax.view_init(20, 60)\n",
    "    ax.grid(False)\n",
    "\n",
    "    start = np.array([results['A'][0], results['B'][0], results['C'][0]])\n",
    "    end = np.array([results['A'][-1], results['B'][-1], results['C'][-1]])\n",
    "    ax.scatter(*start, c='g', edgecolor='k', label='start')\n",
    "    ax.scatter(*end, c='r', edgecolor='k', label='end')\n",
    "\n",
    "    t_max = 20\n",
    "    start = start / n\n",
    "    sol = solve_ivp(odes, [0,t_max], start, dense_output=True)\n",
    "    ax.plot(*(sol.sol(np.linspace(0,t_max,100 * t_max)) * n + 0.001*n), color='k', label='ODE trajectory', lw=1)\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    return(fig, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = phase_plot(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In phase space the dynamics live on the simplex $A+B+C=n$.\n",
    "The ODE solutions are neutrally stable orbits, wheras the true dynamics have a randomly fluctuating amplitude. On a sufficiently long timescale, this leads to a stark qualitative difference. The ODE will oscillate indefinitely, but the true stochastic dynamics will eventually crash, with one species taking over, hitting one of the corners of the simplex. We can tell `ppsim` to run without a time bound to see how long it runs before crashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 ** 4\n",
    "dist = [0.2, 0.3, 0.5]\n",
    "init_config = {a: n * dist[0], b: n * dist[1], c: n * dist[2]}\n",
    "sim = pp.Simulation(init_config, rps)\n",
    "sim.run()\n",
    "sim.history.plot(figsize = (12,4), linewidth=0.5)\n",
    "plt.ylim(0, n)\n",
    "plt.title('rps oscillator')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take a look a larger population size of one million. Here `ppsim` is able to simulate out to time 300 in about 1 second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 ** 6\n",
    "dist = [0.2, 0.3, 0.5]\n",
    "init_config = {a: n * dist[0], b: n * dist[1], c: n * dist[2]}\n",
    "sim = pp.Simulation(init_config, rps)\n",
    "%time sim.run(300, 0.01)\n",
    "sim.history.plot(figsize = (15,4))\n",
    "plt.ylim(0, n)\n",
    "plt.title('rps oscillator')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this scale, the plot does not look qualitatively different from the ODEs. But if we take a closer look in phase space, we can still see that the orbits are fluctuating randomly. These fluctuations would not appear in the ODE solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sim.history['A'],sim.history['B'], label='sample trajectory')\n",
    "init_a, init_b = sim.history['A'][0], sim.history['B'][0]\n",
    "plt.scatter(init_a, init_b, color='g', zorder=4, edgecolor='k', label='start')\n",
    "r = 10 ** 4\n",
    "plt.xlim(init_a - r, init_a + r)\n",
    "plt.ylim(init_b - r, init_b + r)\n",
    "plt.xlabel('Count of A')\n",
    "plt.ylabel('Count of B')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\tau$-leaping attempts to model the stochastic trajectories, with a speedup that assumes propensities do not change over longer periods. Here we set the `tau_tol` parameter for GillesPy2 `TauLeapingSolver` to yield a simulation time of about 1 second, comparable to `ppsim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gillespy2\n",
    "n = 10 ** 6\n",
    "dist = [0.2, 0.3, 0.5]\n",
    "init_config = {a: n * dist[0], b: n * dist[1], c: n * dist[2]}\n",
    "model = pp.gillespy2_format(init_config, rps, n)\n",
    "model.timespan(np.linspace(0,300,3000))\n",
    "%time results=model.run(solver=gillespy2.TauLeapingSolver, tau_tol = 0.02)\n",
    "results.plot(figsize = (15, 4))\n",
    "fig, ax = phase_plot(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show a very clear and steady outward drift, that was not present in the true dynamics. This will cause the system to crash much sooner than the true stochastic system.\n",
    "\n",
    "Simulating for a longer period of time, we can the system go extinct in less than $\\sqrt{n}$ time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 ** 6\n",
    "dist = [0.2, 0.3, 0.5]\n",
    "init_config = {a: n * dist[0], b: n * dist[1], c: n * dist[2]}\n",
    "model = pp.gillespy2_format(init_config, rps, n)\n",
    "model.timespan(np.linspace(0,1000,1000))\n",
    "results=model.run(solver=gillespy2.TauLeapingSolver,tau_tol = 0.02)\n",
    "results.plot(figsize = (15, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that similar issues will come up with attempts to simulate the ODEs for long periods, where numerical errors build up and cause a bias that keeps the system from remaining in one orbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSD oscillator \n",
    "\n",
    "This rock-paper-scissors (RPS) oscillator was implemented using DNA strand displacement in http://dx.doi.org/10.1126/science.aal2052 (bioRxiv verion: https://www.biorxiv.org/content/10.1101/138420v2). Figure 1 from the paper gives a quick summary:\n",
    "\n",
    "<img src=\"https://science.sciencemag.org/content/sci/358/6369/eaal2052/F1.large.jpg\" width=\"600\" />\n",
    "\n",
    "The implementation (itself also using only 2-input/2-output reactions) uses 45 total DNA species with 8 DNA reactions per formal reaction above (i.e., 24 total DNA reactions).\n",
    "Our simulation uses the same concentrations (around 10-100 nM), though a somewhat smaller volume by a few orders of magnitude (10 nL) than that used in the real experiment.\n",
    "Under these conditions the simulation is close to real-time:\n",
    "a couple seconds of real time per second of simulated time.\n",
    "(Since the actual experiment ran for hours, this was taxing even for our algorithm.)\n",
    "For simplicity we did not include the full set of simulated reactions (such as leak reactions and toehold occlusion reactions) described in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppsim import species\n",
    "# Fig. 1 in https://www.biorxiv.org/content/10.1101/138420v2.full.pdf\n",
    "# A+B --> 2B\n",
    "# B+C --> 2C\n",
    "# C+A --> 2A\n",
    "\n",
    "# signal species (represent formal species in formal CRN above)\n",
    "# index indicates whether it was the first or second product of a previous reaction\n",
    "b1, b2, c1, c2, a1, a2 = pp.species('b1  b2  c1  c2  a1  a2')\n",
    "\n",
    "signal_species = [b1, b2, c1, c2, a1, a2]\n",
    "\n",
    "# fuel species react step\n",
    "react_a_b_b1, back_a_b = species('react_a_b_b1  back_a_b')\n",
    "react_b_c_c1, back_b_c = species('react_b_c_c1  back_b_c')\n",
    "react_c_a_a1, back_c_a = species('react_c_a_a1  back_c_a')\n",
    "\n",
    "react_species = [react_a_b_b1, react_b_c_c1, react_c_a_a1]\n",
    "back_species = [back_a_b, back_b_c, back_c_a]\n",
    "\n",
    "# fuel species produce step\n",
    "produce_b_b1_b2, helper_b_b2 = species('produce_b_b1_b2  helper_b_b2')\n",
    "produce_c_c1_c2, helper_c_c2 = species('produce_c_c1_c2  helper_c_c2')\n",
    "produce_a_a1_a2, helper_a_a2 = species('produce_a_a1_a2  helper_a_a2')\n",
    "\n",
    "produce_species = [produce_b_b1_b2, produce_c_c1_c2, produce_a_a1_a2]\n",
    "helper_species = [helper_b_b2, helper_c_c2, helper_a_a2]\n",
    "fuel_species = react_species + produce_species\n",
    "\n",
    "# intermediate species\n",
    "flux_b_b1, flux_c_c1, flux_a_a1 = species('flux_b_b1  flux_c_c1  flux_a_a1')\n",
    "reactint_a1_b_b1, reactint_b1_c_c1, reactint_c1_a_a1 = species('reactint_a1_b_b1  reactint_b1_c_c1  reactint_c1_a_a1') \n",
    "reactint_a2_b_b1, reactint_b2_c_c1, reactint_c2_a_a1 = species('reactint_a2_b_b1  reactint_b2_c_c1  reactint_c2_a_a1') \n",
    "productint_b_b1_b2, productint_c_c1_c2, productint_a_a1_a2 = species('productint_b_b1_b2  productint_c_c1_c2  productint_a_a1_a2')\n",
    "\n",
    "flux_species = [flux_b_b1, flux_c_c1, flux_a_a1]\n",
    "reactint_species = [reactint_a1_b_b1, reactint_b1_c_c1, reactint_c1_a_a1,\n",
    "                    reactint_a2_b_b1, reactint_b2_c_c1, reactint_c2_a_a1]\n",
    "produceint_species = [productint_b_b1_b2, productint_c_c1_c2, productint_a_a1_a2]\n",
    "\n",
    "# waste species react step\n",
    "waste_a1_b1, waste_a1_b2, waste_a2_b1, waste_a2_b2 = species('waste_a1_b1  waste_a1_b2  waste_a2_b1  waste_a2_b2')\n",
    "waste_b1_c1, waste_b1_c2, waste_b2_c1, waste_b2_c2 = species('waste_b1_c1  waste_b1_c2  waste_b2_c1  waste_b2_c2')\n",
    "waste_c1_a1, waste_c1_a2, waste_c2_a1, waste_c2_a2 = species('waste_c1_a1  waste_c1_a2  waste_c2_a1  waste_c2_a2')\n",
    "\n",
    "# waste species produce step\n",
    "waste_b_b1_b2, waste_c_c1_c2, waste_a_a1_a2 = species('waste_b_b1_b2  waste_c_c1_c2  waste_a_a1_a2')\n",
    "\n",
    "waste_species = [waste_a1_b1, waste_a1_b2, waste_a2_b1, waste_a2_b2,\n",
    "                 waste_b1_c1, waste_b1_c2, waste_b2_c1, waste_b2_c2,\n",
    "                 waste_c1_a1, waste_c1_a2, waste_c2_a1, waste_c2_a2,\n",
    "                 waste_b_b1_b2, waste_c_c1_c2, waste_a_a1_a2]\n",
    "\n",
    "# DSD reactions implementing formal CRN\n",
    "# A+B --> 2B\n",
    "ab_react_rxns = [\n",
    "    a1 + react_a_b_b1 | back_a_b + reactint_a1_b_b1,\n",
    "    a2 + react_a_b_b1 | back_a_b + reactint_a2_b_b1,\n",
    "    reactint_a1_b_b1 + b1 >> waste_a1_b1 + flux_b_b1, # typo in Fig. 1; these rxns irreversible\n",
    "    reactint_a1_b_b1 + b2 >> waste_a1_b2 + flux_b_b1, #\n",
    "    reactint_a2_b_b1 + b1 >> waste_a2_b1 + flux_b_b1, #\n",
    "    reactint_a2_b_b1 + b2 >> waste_a2_b2 + flux_b_b1, #\n",
    "]\n",
    "ab_produce_rxns = [\n",
    "    flux_b_b1 + produce_b_b1_b2 | b1 + productint_b_b1_b2,\n",
    "    helper_b_b2 + productint_b_b1_b2 >> waste_b_b1_b2 + b2,\n",
    "]\n",
    "ab_rxns = ab_react_rxns + ab_produce_rxns\n",
    "\n",
    "# B+C --> 2C\n",
    "bc_react_rxns = [\n",
    "    b1 + react_b_c_c1 | back_b_c + reactint_b1_c_c1,\n",
    "    b2 + react_b_c_c1 | back_b_c + reactint_b2_c_c1,\n",
    "    reactint_b1_c_c1 + c1 >> waste_b1_c1 + flux_c_c1,\n",
    "    reactint_b1_c_c1 + c2 >> waste_b1_c2 + flux_c_c1,\n",
    "    reactint_b2_c_c1 + c1 >> waste_b2_c1 + flux_c_c1,\n",
    "    reactint_b2_c_c1 + c2 >> waste_b2_c2 + flux_c_c1,\n",
    "]\n",
    "bc_produce_rxns = [\n",
    "    flux_c_c1 + produce_c_c1_c2 | c1 + productint_c_c1_c2,\n",
    "    helper_c_c2 + productint_c_c1_c2 >> waste_c_c1_c2 + c2,\n",
    "]\n",
    "bc_rxns = bc_react_rxns + bc_produce_rxns\n",
    "\n",
    "# C+A --> 2A\n",
    "ca_react_rxns = [\n",
    "    c1 + react_c_a_a1 | back_c_a + reactint_c1_a_a1,\n",
    "    c2 + react_c_a_a1 | back_c_a + reactint_c2_a_a1,\n",
    "    reactint_c1_a_a1 + a1 >> waste_c1_a1 + flux_a_a1,\n",
    "    reactint_c1_a_a1 + a2 >> waste_c1_a2 + flux_a_a1,\n",
    "    reactint_c2_a_a1 + a1 >> waste_c2_a1 + flux_a_a1,\n",
    "    reactint_c2_a_a1 + a2 >> waste_c2_a2 + flux_a_a1,\n",
    "]\n",
    "ca_produce_rxns = [\n",
    "    flux_a_a1 + produce_a_a1_a2 | a1 + productint_a_a1_a2,\n",
    "    helper_a_a2 + productint_a_a1_a2 >> waste_a_a1_a2 + a2,\n",
    "]\n",
    "ca_rxns = ca_react_rxns + ca_produce_rxns\n",
    "\n",
    "all_rps_dsd_rxns = ab_rxns + bc_rxns + ca_rxns\n",
    "\n",
    "all_species = signal_species + \\\n",
    "              react_species + \\\n",
    "              back_species + \\\n",
    "              produce_species + \\\n",
    "              helper_species + \\\n",
    "              flux_species + \\\n",
    "              reactint_species + \\\n",
    "              produceint_species + \\\n",
    "              waste_species\n",
    "\n",
    "# These functions map states to categories, which allow HistoryPlotter to show a simplified plot of categories\n",
    "def aux(state):\n",
    "    if state in react_species:\n",
    "        return 'react'\n",
    "    if state in produce_species:\n",
    "        return 'produce'\n",
    "    if state in waste_species:\n",
    "        return 'waste'\n",
    "    if state in helper_species:\n",
    "        return 'helper'\n",
    "    \n",
    "def abc(state):\n",
    "    if state in signal_species:\n",
    "        return state.name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppsim import Simulation, RateConstantUnits, concentration_to_count\n",
    "\n",
    "uL = 10 ** -6  # 1 uL (microliter)\n",
    "nL = 10 ** -9\n",
    "nM = 10 ** -9  # 1 nM (nanomolar)\n",
    "\n",
    "k = 1e6  # forward rate constant in mass-action units\n",
    "r = 1e6  # reverse rate constant in mass-action units\n",
    "for rxn in all_rps_dsd_rxns:\n",
    "    rxn.k(k, units=RateConstantUnits.mass_action)\n",
    "    if rxn.reversible:\n",
    "        rxn.r(r, units=RateConstantUnits.mass_action)\n",
    "\n",
    "vol = 10 * nL\n",
    "\n",
    "# scale time to make simulations take less time\n",
    "time_scaling = 1\n",
    "vol /= time_scaling\n",
    "\n",
    "react_conc = 100 * nM\n",
    "back_conc = 100 * nM\n",
    "helper_conc = 75 * nM\n",
    "produce_conc = 100 * nM\n",
    "a1_conc = 11 * nM\n",
    "b1_conc = 10 * nM\n",
    "c1_conc = 3 * nM\n",
    "\n",
    "# this factor scales all concentrations\n",
    "conc_factor = 1\n",
    "\n",
    "react_count = concentration_to_count(react_conc * conc_factor, vol)\n",
    "back_count = concentration_to_count(back_conc * conc_factor , vol)\n",
    "helper_count = concentration_to_count(helper_conc* conc_factor, vol)\n",
    "produce_count = concentration_to_count(produce_conc* conc_factor, vol)\n",
    "a1_count = concentration_to_count(a1_conc* conc_factor, vol)\n",
    "b1_count = concentration_to_count(b1_conc* conc_factor, vol)\n",
    "c1_count = concentration_to_count(c1_conc* conc_factor, vol)\n",
    "\n",
    "init_config_react = {specie: react_count for specie in react_species}\n",
    "init_config_back = {specie: back_count for specie in back_species}\n",
    "init_config_helper = {specie: helper_count for specie in helper_species}\n",
    "init_config_produce = {specie: produce_count for specie in produce_species}\n",
    "\n",
    "init_config = {a1: a1_count, b1: b1_count, c1: c1_count}\n",
    "init_config.update(init_config_react)\n",
    "init_config.update(init_config_back)\n",
    "init_config.update(init_config_helper)\n",
    "init_config.update(init_config_produce)\n",
    "\n",
    "sim = Simulation(init_config=init_config, rule=all_rps_dsd_rxns, volume=vol, time_units='seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the there is over a 99% chance of a null reaction. Thus, similar to `bimolecular_chain`, this example is among the hardest cases for `ppsim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.null_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code that generated the data, saved with pickle\n",
    "# # Run for 12 simulated hours, recording every 60 seconds\n",
    "# sim.run(12 * 3600, 60)\n",
    "# hp = pp.HistoryPlotter(abc, update_time=1)\n",
    "# hp2 = pp.HistoryPlotter(aux, update_time=1)\n",
    "# sim.add_snapshot(hp)\n",
    "# sim.add_snapshot(hp2)\n",
    "# hp.ax.set_title('Counts of formal species')\n",
    "# hp2.ax.set_title('Counts of auxilliary species')\n",
    "# pickle.dump(sim, open( \"crn_data/dsd_experiment.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = pd.read_pickle( open( \"crn_data/dsd_experiment.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ppsim-venv)",
   "language": "python",
   "name": "ppsim-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
